{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6329e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import march_madness as mm\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188688f",
   "metadata": {},
   "source": [
    "This document is based on work for a Kaggle competition: [March Machine Learning Mania 2022](https://www.kaggle.com/competitions/mens-march-mania-2022)\n",
    "\n",
    "The goal of this project is to predict the results of match-ups in the College Basketball March Madness Tournament.\n",
    "\n",
    "Model performance is scored by a cost function that accumulates based on the correctness and confidence of a prediction. A confident, correct prediction has a minimal cost compared to a confident, incorrect prediction that has a high cost. The confidence of the models prediction for a game outcome is passes as a value from 0 to 1. \n",
    "\n",
    "Given I had a short period of time before the submission deadline (less than three weeks) and limited time to work on the project, I focused my strategy on developing features in a logical progression from simple and high-level towards more complex as I had time. An added benefit of this approach was I was able to test the performance of the model each step along the way as it \"learned\" more information about the teams.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b617a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = mm.Analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad68913",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.load_seasons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14f6575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985\n",
      "1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994\n",
      "1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n",
      "1998\n",
      "1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "2007\n",
      "2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "analysis.calc_seasons_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270e751",
   "metadata": {},
   "source": [
    "# Baseline Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8acf2",
   "metadata": {},
   "source": [
    "Before getting started with models, I wanted to establish two baseline cases.\n",
    "\n",
    "The first is for the coin flip case where both teams are give a 50/50 chance of winning or a 0.5 probability. Hopefully our model performance will be much better than this.\n",
    "\n",
    "The second baseline gives a prediction based solely on the historical rate that one tournament seed defeated another. In the case where two teams with the same seed played each other or there were less than five historical match-ups between a pair of seeds, the neutral probability of 0.5 was used for the match-up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277ed46",
   "metadata": {},
   "source": [
    "## 50/50 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a9d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56525d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac74251",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b782519",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_predictions = np.ones(y_test.shape) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "becd74e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,naive_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d530b0",
   "metadata": {},
   "source": [
    "## Seed Win Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e110465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7741f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672e741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7660a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_predictions = analysis.generate_seed_win_predictions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e4c7e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5343585507841929"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,seed_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf48ab",
   "metadata": {},
   "source": [
    "The results for the predictions based solely on the historical seed match-ups were actually quite good however there is undoubtably over-fitting occuring since the test set games were included when these percentages were calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e4c5a",
   "metadata": {},
   "source": [
    "So instead of using historically calculated seed win-percentages, I started with a logistic regression model using only the seed information for the two teams. I took two approaches to see if there was a significant difference, the first where I treated the seeding as a continuous variable and the second where I treated it as a categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b36151",
   "metadata": {},
   "source": [
    "## Seed Only (As Continuous Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5efea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fadb4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2304ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e113fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5eea8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff2e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9afcff3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acc91351",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6357de01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7081174438687392"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "097bc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7275862068965517"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5265632",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c08208d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5486250962043996"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b9e13",
   "metadata": {},
   "source": [
    "## Seed Only (As Categorical Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b34f0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "796b9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1259e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21bc6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03a0c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cafd4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26b9766f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c0524a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "497defaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faa48a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9787c07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7092688543465746"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afa1c97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7224137931034482"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8ca3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd912c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5460612329616418"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d4c70",
   "metadata": {},
   "source": [
    "The results were essentially the same between the two cases, indicating there isn't a huge difference either way. For the rest of the way, I treat the seed as a continuous variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14152c98",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a74a4a",
   "metadata": {},
   "source": [
    "I started feature engineering by recreating the [RPI Rating system](https://en.wikipedia.org/wiki/Rating_percentage_index) that was a common measure used to compare, select, and seed teams in the NCAA tournament through 2018.\n",
    "\n",
    "RPI is made up of three components:\n",
    "* Team weighted win percentage (Road wins count as 1.4 vs 0.6 for home wins)\n",
    "* Opponents Win Percentage (OWP)\n",
    "* Opponents-Opponents Win Percentage (OOWP)\n",
    "\n",
    "In addition to being a common and accepted comparison system, calculating variables for RPI was a good place to start because it captures information on the teams' win/loss record, as well as, their Strength of Schedule (OWP & OOWP)\n",
    "\n",
    "The rest of the way, I test my feature set on both a logistic regression model and a random forest classifier. I fully expected the random forest to overfit, especially on small feature sets, but I hoped I would see it begin to generalize as more features and information was added.\n",
    "\n",
    "I chose these two models to primarily work with because:\n",
    "* The logistic regression is simple, easy to interpret, and at the very least will serve as a performance baseline for more advanced models.\n",
    "* Random Forests have general high performance and robustness, and in particular, are able to utilize a large number of features and determine which are the most relevant to the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839f628",
   "metadata": {},
   "source": [
    "## RPI (No Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39541cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['weighted win pct','owp','oowp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5b92c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1de3983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8e6a7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12d2469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "447fd442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddf75f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be465d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a49ed7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7012089810017271"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab70e1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7206896551724138"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "801a87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10,max_features=3,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09c1de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9890616004605642"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9cb9d4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6517241379310345"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d368b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75f0e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80acedbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5704323253772825"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "570bfb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6490043542700804"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e968d26c",
   "metadata": {},
   "source": [
    "Interestingly using the RPI variables had slightly worse performance than seed alone. The percentage of correct values was nearly the same, however, the score based on the confidence of predictions actually suffered. I added back the seed to see how it helps the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252adf1",
   "metadata": {},
   "source": [
    "## RPI + Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "151d9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78fa81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70182fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ff58684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fdb1fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64f45de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "552af895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fce6bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85c6fb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7081174438687392"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f658d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7275862068965517"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31a6f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10,max_features=3,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f6a2f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982153137593552"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4aa3d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896551724137931"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4cfb39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4dbed251",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "484b185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5435766503043533"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c40f804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6093238041423586"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6ec3b",
   "metadata": {},
   "source": [
    "Adding the seed back into the RPI calculation brought the prediction score back to nearly equivalent to the seed alone. Interestingly the RPI features didn't improve the performance of the model possibly because a lot of this information is baked into the process of seeding the teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50535bcd",
   "metadata": {},
   "source": [
    "## Margin of Victory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e72e3a",
   "metadata": {},
   "source": [
    "The next step was to add in features capturing the magnitude of the teams' wins and losses. Features inclueded the avg margin of wins and losses, as well as, the number of \"close\" wins and losses defined as 3pts or less. These features didn't have a significant impact on the performance of the logistic regression model but it was the first time the random forest had comparable performance even though it is still over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84d48dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','avg win margin','std win margin','avg loss margin',\n",
    "                'std loss margin','capped avg win margin','capped std win margin','capped avg loss margin',\n",
    "                'capped std loss margin','close wins','close losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f6e9aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef53e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdb1bd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "617799a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c4aa992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 28)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ceb2fd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3dab9484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c6c0ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7098445595854922"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cfe817cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7103448275862069"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c3d858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100,max_features=3,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "361c45c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58ead38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06a2ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "991c532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f04403e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53703161885065"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88c62083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5516808324210644"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ff2d5",
   "metadata": {},
   "source": [
    "## Quality Wins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3a3a4",
   "metadata": {},
   "source": [
    "Next we want to add information about wins and losses a team has against top seeded teams and other teams in the tournament. These wins, especially those against the top 16 and top 8 teams would be characterized as \"quality\" wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8eb64854",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','avg win margin','std win margin','avg loss margin',\n",
    "                'std loss margin','capped avg win margin','capped std win margin','capped avg loss margin',\n",
    "                'capped std loss margin','close wins','close losses','weighted top64 wins','weighted top32 wins',\n",
    "                'weighted top16 wins','weighted top8 wins','weighted top64 losses','weighted top32 losses',\n",
    "                'weighted top16 losses','weighted top8 losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "81f6f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4923cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5edbaf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 44)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd069b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a609e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 44)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe43bf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "417cdd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "685ea18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7248128957973518"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "005b1233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7103448275862069"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aca8fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,max_features=3,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "78dde3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "782ad585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7034482758620689"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4d0df282",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b1cb09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3860e635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5360929662801386"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e3fe82f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.550411175513449"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f422723",
   "metadata": {},
   "source": [
    "## Late Season Form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ff8db",
   "metadata": {},
   "source": [
    "Finally, features on the the late season form of the teams is added to capture how \"hot\" each team is going into the tournament. This includeds their win percentage over the last 5 and 10 games, as well as, how they performed in their conference tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c7394bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','avg win margin','std win margin','avg loss margin',\n",
    "                'std loss margin','capped avg win margin','capped std win margin','capped avg loss margin',\n",
    "                'capped std loss margin','close wins','close losses','weighted top64 wins','weighted top32 wins',\n",
    "                'weighted top16 wins','weighted top8 wins','weighted top64 losses','weighted top32 losses',\n",
    "                'weighted top16 losses','weighted top8 losses','last10 win pct','last10 weighted win pct',\n",
    "                'last5 win pct','last5 weighted win pct','conference tourney wins','conference champ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7971d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "504bbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "136550f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 56)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4befb2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "80e02149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 56)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bc1797ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a59cffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0bea6e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7276914219919401"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe10cbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696551724137931"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2de022f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,max_features=3,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3e2144fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3696b8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155172413793104"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bf803085",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dc7b2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "48550715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416041357563278"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "581521b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5509841947134376"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5be948",
   "metadata": {},
   "source": [
    "Interestingly enought, the model performance was actually slightly worse with the additional features. I'm not sure how much to read into this but I feel like I have extracted most of the value from the final score lines alone.\n",
    "\n",
    "Since this is where I got to before running into the deadline to submit the prediction before the tournament began, I first tested to see if removing some of the more redundent features helped the logistic regression model, and second, tested a range of regularization parameters to see which yielded the best performance for my submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02627461",
   "metadata": {},
   "source": [
    "## Pruned Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dd52e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','capped avg win margin','capped std win margin',\n",
    "                'capped avg loss margin','capped std loss margin','close wins','close losses','weighted top64 wins',\n",
    "                'weighted top16 wins','weighted top64 losses','weighted top16 losses','last10 weighted win pct',\n",
    "                'last5 weighted win pct','conference tourney wins','conference champ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "da020f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb1963a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "45965901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 36)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5f292d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "195efe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 36)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "700467ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "016b7b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1e509100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717328727691422"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "adc41ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120689655172414"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "446501d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = round(np.sqrt(len(feature_keys)))\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "418e5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,max_features=3,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "109b4d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0aca127d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f1945df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a2ae342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d2108860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5403244678454653"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8ec86f2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5514995313178037"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41024d2",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e3447",
   "metadata": {},
   "source": [
    "From pruning the features, I didn't see a significant improvement in the logistic regression performance. Admitidly, I didn't have time to investigate which feature where having the largest effect on the data which would've been helpful for that selection. Since there doesn't seem to be over-fitting occuring with the logistic regression model, I decided to include the entire feature set. The random forest model is still over-fitting even when controlling the 'max_features' parameter to 3. Therefore, it looks like the logistic regression model is the way to go at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1ea4e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','avg win margin','std win margin','avg loss margin',\n",
    "                'std loss margin','capped avg win margin','capped std win margin','capped avg loss margin',\n",
    "                'capped std loss margin','close wins','close losses','weighted top64 wins','weighted top32 wins',\n",
    "                'weighted top16 wins','weighted top8 wins','weighted top64 losses','weighted top32 losses',\n",
    "                'weighted top16 losses','weighted top8 losses','last10 win pct','last10 weighted win pct',\n",
    "                'last5 win pct','last5 weighted win pct','conference tourney wins','conference champ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e9a7d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.seasons_generate_tourney_model_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f2be943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8b00c9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 56)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7e6ae346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3640a45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 56)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "37b83981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f8487c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_values = [10**x for x in range(-4,5)]\n",
    "C_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7ceb9c37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization Value: 0.0001\n",
      "Training Score: 0.705\n",
      "Test Score: 0.705\n",
      "Predictions Score: 0.540\n",
      "\n",
      "Regularization Value: 0.001\n",
      "Training Score: 0.707\n",
      "Test Score: 0.707\n",
      "Predictions Score: 0.540\n",
      "\n",
      "Regularization Value: 0.01\n",
      "Training Score: 0.718\n",
      "Test Score: 0.718\n",
      "Predictions Score: 0.540\n",
      "\n",
      "Regularization Value: 0.1\n",
      "Training Score: 0.725\n",
      "Test Score: 0.725\n",
      "Predictions Score: 0.540\n",
      "\n",
      "Regularization Value: 1\n",
      "Training Score: 0.728\n",
      "Test Score: 0.728\n",
      "Predictions Score: 0.540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization Value: 10\n",
      "Training Score: 0.728\n",
      "Test Score: 0.728\n",
      "Predictions Score: 0.540\n",
      "\n",
      "Regularization Value: 100\n",
      "Training Score: 0.727\n",
      "Test Score: 0.727\n",
      "Predictions Score: 0.540\n",
      "\n",
      "Regularization Value: 1000\n",
      "Training Score: 0.728\n",
      "Test Score: 0.728\n",
      "Predictions Score: 0.540\n",
      "\n",
      "Regularization Value: 10000\n",
      "Training Score: 0.728\n",
      "Test Score: 0.728\n",
      "Predictions Score: 0.540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for C in C_values:\n",
    "    logreg = LogisticRegression(C=C).fit(X_train,y_train)\n",
    "    \n",
    "    print(f'Regularization Value: {C}')\n",
    "    print(f'Training Score: {logreg.score(X_train,y_train):.3f}')\n",
    "    print(f'Test Score: {logreg.score(X_train,y_train):.3f}')\n",
    "    print(f'Predictions Score: {analysis.score_model_predictions(y_test,logreg_pred):.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71078f",
   "metadata": {},
   "source": [
    "In this case, a higher regularization value was better but didn't show model improvement above the default C=1 so I decided to leave the default parameter as-is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bbd27d",
   "metadata": {},
   "source": [
    "# Development Phase 1 - Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043e9a1",
   "metadata": {},
   "source": [
    "For this phase, the models were trained using features created from game summary data (who won and the score). The features were derived from regular season data because when we go to make predictions on new tournaments, that's the only data we will have. However, after the features were created using each seasons' regular season games, only match-ups in the historical NCAA tournaments were used to train how these features can be used to predict tournament outcomes.\n",
    "\n",
    "Information generated from the game summary data included:\n",
    "* Overall team season performance (win %, weighted win %)\n",
    "* Team strength of schedule\n",
    "* Team win and loss margins\n",
    "* How many 'quality' wins a team had\n",
    "* The late season form of a team entering the tournament\n",
    "\n",
    "\n",
    "One thing that was clear was the importance of the team's seed to game prediction, even over some of the more intuitively descriptive features of a teams quality. A likely explanation for this is that a lot of the information about the historical performance of a team over the season is baked into the their tournament seed, and by extension, their overall National ranking and standings in aggregate rating systems that were used to by the tournament selection committe to make the seeding decisions.\n",
    "\n",
    "\n",
    "Although we were able to achieve modest performance improvements compared to just the seed or random guesses, particularly in regard to refining the confidence of our predictions, it wasn't overwhelmingly good. It's pretty clear that to achieve the type of improved predictive performance we would hope to get using machine learning, additional and more detailed information about the teams' performance is needed. This information will hopefully improve our model by not just utilizing game outcome information, but rather information about how the teams achieved those outcomes, which could be a significant factor in how two teams match-up in the context of the game, rather than just their wins and losses over the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bbfb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
