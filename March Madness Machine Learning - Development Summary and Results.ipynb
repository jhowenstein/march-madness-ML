{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45135fe",
   "metadata": {},
   "source": [
    "# March Madness Machine Learning - Development Summary and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be9feb",
   "metadata": {},
   "source": [
    "# Competition Overview\n",
    "\n",
    "This document is based on work for a Kaggle competition: [March Machine Learning Mania 2022](https://www.kaggle.com/competitions/mens-march-mania-2022)\n",
    "\n",
    "The goal of this project was to predict the results of match-ups in the College Basketball March Madness Tournament.\n",
    "\n",
    "Model performance is scored by a cost function that accumulates based on the correctness and confidence of a prediction. A confident, correct prediction has a minimal cost compared to a confident, incorrect prediction that has a high cost. The confidence of the models prediction for a game outcome is passes as a value from 0 to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943ae57",
   "metadata": {},
   "source": [
    "## Development Process\n",
    "\n",
    "Based on time constraints, I broke up the devepment of this project into two phases:\n",
    "* Phase 1: Models were built using the 'compact game results' from past seasons. This data included which team won and the points scored by the winning and losing team.\n",
    "* Phase 2: Models were built using the 'detailed game results' froom past seasons. This included stats such as the number of field goals made, blocks, steals, free throws, etc.\n",
    "\n",
    "For feature set during development, I tested both a Logistic Regression and a Random Forrest Classifier model.\n",
    "\n",
    "I chose these two models to primarily work with because:\n",
    "* The logistic regression is simple, easy to interpret, and at the very least will serve as a performance baseline for more advanced models.\n",
    "* Random Forests have general high performance and robustness, and in particular, are able to utilize a large number of features and determine which are the most relevant to the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e6b39",
   "metadata": {},
   "source": [
    "## Additional Notebooks\n",
    "\n",
    "This notebook summarizes key trained models and the ensueing results for the actual 2022 NCCA Men's Tournament.\n",
    "\n",
    "For a detailed look at my process for developing a model for Phase 1:\n",
    "https://github.com/jhowenstein/march-madness-ML/blob/main/March%20Madness%20-%20Phase%201%20-%20Process%20Write-Up.ipynb\n",
    "\n",
    "For a detailed look at my process for developing a model for Phase 2:\n",
    "https://github.com/jhowenstein/march-madness-ML/blob/main/March%20Madness%20-%20Phase%201%20-%20Post%20Tournament%20Review.ipynb\n",
    "\n",
    "For a complete review of my Phase 1 model performance in the 2022 NCAA Tournament:\n",
    "https://github.com/jhowenstein/march-madness-ML/blob/main/March%20Madness%20-%20Initial%20Submission%20-%20Post%20Tournament%20Review.ipynb\n",
    "\n",
    "For a complete review of my Phase 2 model performance in the 2022 NCAA Tournament:\n",
    "https://github.com/jhowenstein/march-madness-ML/blob/main/March%20Madness%20-%20Phase%202%20-%20Post%20Tournament%20Review.ipynb\n",
    "\n",
    "For the code I used to calculate the model features for each team and season:\n",
    "https://github.com/jhowenstein/march-madness-ML/blob/main/march_madness.py\n",
    "\n",
    "For the notebook I used to calculate and save a csv fill all the feature data:\n",
    "https://github.com/jhowenstein/march-madness-ML/blob/main/March%20Madness%20-%20Feature%20Calculation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4020c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import march_madness as mm\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fb8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = mm.Analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb827253",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.load_training_data('MDataFiles_Stage2/calculated features 1985-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0b0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.load_validation_data('MDataFiles_Stage2/calculated features 2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a027c948",
   "metadata": {},
   "source": [
    "# Phase 1 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d2b08",
   "metadata": {},
   "source": [
    "## Final Training Models\n",
    "\n",
    "The four models below are my final training models for Phase 1 of development. Note: After model selection, I did retrain the selected model on all the training data before generating predictions for the 2022 Tournament. \n",
    "\n",
    "The Logistic Regression models had the best training scores but I was concerned they may not generalize as well given the highly correlated nature of some of the features. I did try pruning the feature set of some of the highly correlated or similar features and saw some modest improvements. Unfortunately I didn't have a lot of time to explore this before the submission deadline and ultimately decided to see how my submission using the Logistic Regression model would perform using the full feature set.\n",
    "\n",
    "The Random Forest models performed slightly worse and in the case of the model controlled by limiting 'max_features', over-fitting of the training set was still occurring which was a concern for generalization. After the submission deadline, I explored using 'max_depth' to control the model complexity and it appeared to be very effective for limiting over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd4754",
   "metadata": {},
   "source": [
    "### Using All Calculated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27554b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','avg win margin','std win margin','avg loss margin',\n",
    "                'std loss margin','capped avg win margin','capped std win margin','capped avg loss margin',\n",
    "                'capped std loss margin','close wins','close losses','weighted top64 wins','weighted top32 wins',\n",
    "                'weighted top16 wins','weighted top8 wins','weighted top64 losses','weighted top32 losses',\n",
    "                'weighted top16 losses','weighted top8 losses','last10 win pct','last10 weighted win pct',\n",
    "                'last5 win pct','last5 weighted win pct','conference tourney wins','conference champ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed6f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.extract_training_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5adabfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88287249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 56)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463821b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62886aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 56)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66460d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5c872",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e171752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f67512fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7276914219919401"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a009ad65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696551724137931"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a1a9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3845b686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416041357699954"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ba49f",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (max_features controlled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb6a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,max_features=3,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e332d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e89c84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155172413793104"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c723e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14445340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5509841947134376"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4efba",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (max_depth controlled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97414736",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,\n",
    "                                max_features='sqrt',max_depth=5,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb717098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7852619458837076"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c35168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7189655172413794"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7842606",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d902e7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5495379202820174"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c289b16e",
   "metadata": {},
   "source": [
    "### Using Pruned Feature Set (Logistic Regression Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "688b4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','capped avg win margin','capped std win margin',\n",
    "                'capped avg loss margin','capped std loss margin','close wins','close losses','weighted top64 wins',\n",
    "                'weighted top16 wins','weighted top64 losses','weighted top16 losses','last10 weighted win pct',\n",
    "                'last5 weighted win pct','conference tourney wins','conference champ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66520529",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.extract_training_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04bb4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f03b4c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 36)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bad742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "114e9ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 36)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec9f5366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43fb7187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99145e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7184801381692574"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40344cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155172413793104"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "542ecc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24b835b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385360241344801"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a70e55b",
   "metadata": {},
   "source": [
    "## Tournament Results\n",
    "\n",
    "As mentioned above, for all of these models, I retrained them using the entire training set before testing their predictions on the 2022 NCAA Tournament results.\n",
    "\n",
    "I had a bug in my submission code (🤦🏻‍♂️) so my actual score on the leaderboard ended up not being accurate. The results below for the 'Logistic Regression (all features)' is what my score should've been. A total of 930 submissions were entered into the competition.\n",
    "\n",
    "Model Performance: \n",
    "* Logistic Regression (all features)\n",
    "    * Competition Score: 0.67371\n",
    "    * Leaderboard Ranking: 581st\n",
    "* Random Forrest ('max_features' controlled)\n",
    "    * Competition Score: 0.63990\n",
    "    * Leaderboard Ranking: 343rd\n",
    "* Random Forrest ('max_depth' controlled)\n",
    "    * Competition Score: 0.60753\n",
    "    * Leaderboard Ranking: 71st\n",
    "* Logistic Regression (pruned feature set)\n",
    "    * Competition Score: 0.61613\n",
    "    * Leaderboard Ranking: 143rd\n",
    "    \n",
    "In the end, the Logistic Regression model using all the training features performed the worst. The version trained on the pruned feature set performed considerably better and clearly the fewer features helped it generalize. The Random Forest using the 'max_depth' parameter performed the best and actually ended up ranking pretty high compared the competition results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc6510",
   "metadata": {},
   "source": [
    "### Using All Calculated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d0cb626",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','avg win margin','std win margin','avg loss margin',\n",
    "                'std loss margin','capped avg win margin','capped std win margin','capped avg loss margin',\n",
    "                'capped std loss margin','close wins','close losses','weighted top64 wins','weighted top32 wins',\n",
    "                'weighted top16 wins','weighted top8 wins','weighted top64 losses','weighted top32 losses',\n",
    "                'weighted top16 losses','weighted top8 losses','last10 win pct','last10 weighted win pct',\n",
    "                'last5 win pct','last5 weighted win pct','conference tourney wins','conference champ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10339200",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = analysis.extract_training_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22783967",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = analysis.extract_validation_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f552283",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93e3dec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bc4f27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285282693137678"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31a22d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417910447761194"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6d53284",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "105622e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6737052990506176"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bfa928",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (max_features controlled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d89b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,max_features=3,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79c45b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83a94347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6268656716417911"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b608fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef9a2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0f6ee50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6398966806324071"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8afcc",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (max_depth controlled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "339f8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,max_features='sqrt',\n",
    "                                max_depth=5,random_state=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c18604b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734138972809668"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab6d9008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6268656716417911"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afe5f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f96d743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60753019317656"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f0131",
   "metadata": {},
   "source": [
    "### Using Pruned Feature Set (Logistic Regression Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8fd3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','capped avg win margin','capped std win margin',\n",
    "                'capped avg loss margin','capped std loss margin','close wins','close losses','weighted top64 wins',\n",
    "                'weighted top16 wins','weighted top64 losses','weighted top16 losses','last10 weighted win pct',\n",
    "                'last5 weighted win pct','conference tourney wins','conference champ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebe9ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = analysis.extract_training_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "114e1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = analysis.extract_validation_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f7da571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e98075d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7229175658178679"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61820a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716417910447762"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8fbbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = mm.bound_predictions(logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42389363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161292833078834"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,logreg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beccd7d",
   "metadata": {},
   "source": [
    "# Phase 2 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f0e5ac",
   "metadata": {},
   "source": [
    "## Final Training Models\n",
    "\n",
    "For phase two, I added in a significant number of features using the detailed game results. With the additional features, some of which are highly correlated, I went with the Random Forest model due to its general performance and ability to auto-select the most important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7610b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','avg win margin','std win margin','avg loss margin',\n",
    "                'std loss margin','capped avg win margin','capped std win margin','capped avg loss margin',\n",
    "                'capped std loss margin','close wins','close losses','weighted top64 wins','weighted top32 wins',\n",
    "                'weighted top16 wins','weighted top8 wins','weighted top64 losses','weighted top32 losses',\n",
    "                'weighted top16 losses','weighted top8 losses','last10 win pct','last10 weighted win pct',\n",
    "                'last5 win pct','last5 weighted win pct','conference tourney wins','conference champ','Team Avg FGM',\n",
    "                'Team Avg FGA','Team Avg FGM3','Team Avg FGA3','Team Avg FTM','Team Avg FTA',\n",
    "                'Team Avg OR','Team Avg DR','Team Avg Ast','Team Avg TO%','Team Avg Stl%','Team Avg Blk%',\n",
    "                'Team Avg PF','Team Avg TR','Team Avg FGM2','Team Avg FGA2','Team Avg FG%','Team Avg FG2%',\n",
    "                'Team Avg FG3%','Team Avg FGA3%','Team Avg FT%','Team Avg Pos','Team Avg OEff','Opp Avg FGM',\n",
    "                'Opp Avg FGA','Opp Avg FGM3','Opp Avg FGA3','Opp Avg FTM','Opp Avg FTA','Opp Avg OR','Opp Avg DR',\n",
    "                'Opp Avg Ast','Opp Avg TO%','Opp Avg Stl%','Opp Avg Blk%','Opp Avg PF','Opp Avg TR','Opp Avg FGM2',\n",
    "                'Opp Avg FGA2','Opp Avg FG%','Opp Avg FG2%','Opp Avg FG3%','Opp Avg FGA3%','Opp Avg FT%',\n",
    "                'Opp Avg Pos','Opp Avg OEff','Net Team Avg FGM','Net Team Avg FGA','Net Team Avg FGM3',\n",
    "                'Net Team Avg FGA3','Net Team Avg FTM','Net Team Avg FTA','Net Team Avg OR','Net Team Avg DR',\n",
    "                'Net Team Avg Ast','Net Team Avg TO%','Net Team Avg Stl%','Net Team Avg Blk%','Net Team Avg PF',\n",
    "                'Net Team Avg TR','Net Team Avg FGM2','Net Team Avg FGA2','Net Team Avg FG%','Net Team Avg FG2%',\n",
    "                'Net Team Avg FG3%','Net Team Avg FGA3%','Net Team Avg FT%','Net Team Avg Pos','Net Team Avg OEff',\n",
    "                'Net Opp Avg FGM','Net Opp Avg FGA','Net Opp Avg FGM3','Net Opp Avg FGA3','Net Opp Avg FTM',\n",
    "                'Net Opp Avg FTA','Net Opp Avg OR','Net Opp Avg DR','Net Opp Avg Ast','Net Opp Avg TO%',\n",
    "                'Net Opp Avg Stl%','Net Opp Avg Blk%','Net Opp Avg PF','Net Opp Avg TR','Net Opp Avg FGM2',\n",
    "                'Net Opp Avg FGA2','Net Opp Avg FG%','Net Opp Avg FG2%','Net Opp Avg FG3%','Net Opp Avg FGA3%',\n",
    "                'Net Opp Avg FT%','Net Opp Avg Pos','Net Opp Avg OEff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55c73a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = analysis.extract_training_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81da6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2c73112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfdfe0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "714e9448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 29161)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba13a05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d02cb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 29161)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d471ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca10df5",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "796c3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10000,max_features='sqrt',\n",
    "                                max_depth=5,random_state=100,n_jobs=2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ead544a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8485895221646517"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d69649d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155172413793104"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0d1720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad4bed95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5556406069420509"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e21c0a",
   "metadata": {},
   "source": [
    "## Tournament Results\n",
    "\n",
    "Surprisely, the additional information provided using the 'detailed game results' didn't improve the model's performance compared to the Random Forest in Phase 1. However, all four of the Random Forest models I trained using the additional features performed very providing some evidence that the additional information made the models more robust.\n",
    "\n",
    "All four of the Logistic Regression Models I trained actually performed significantly worse than the Random Forest's and the models from Phase 1. This supports the trend we saw in Phase 1 where the Logistic Regression's performance actually tended to decrease as more features were added. \n",
    "\n",
    "Model Performance: \n",
    "* Random Forrest\n",
    "    * Competition Score: 0.61260\n",
    "    * Leaderboard Ranking: 126th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1708d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['tourney seed','weighted win pct','owp','oowp','avg win margin','std win margin','avg loss margin',\n",
    "                'std loss margin','capped avg win margin','capped std win margin','capped avg loss margin',\n",
    "                'capped std loss margin','close wins','close losses','weighted top64 wins','weighted top32 wins',\n",
    "                'weighted top16 wins','weighted top8 wins','weighted top64 losses','weighted top32 losses',\n",
    "                'weighted top16 losses','weighted top8 losses','last10 win pct','last10 weighted win pct',\n",
    "                'last5 win pct','last5 weighted win pct','conference tourney wins','conference champ','Team Avg FGM',\n",
    "                'Team Avg FGA','Team Avg FGM3','Team Avg FGA3','Team Avg FTM','Team Avg FTA',\n",
    "                'Team Avg OR','Team Avg DR','Team Avg Ast','Team Avg TO%','Team Avg Stl%','Team Avg Blk%',\n",
    "                'Team Avg PF','Team Avg TR','Team Avg FGM2','Team Avg FGA2','Team Avg FG%','Team Avg FG2%',\n",
    "                'Team Avg FG3%','Team Avg FGA3%','Team Avg FT%','Team Avg Pos','Team Avg OEff','Opp Avg FGM',\n",
    "                'Opp Avg FGA','Opp Avg FGM3','Opp Avg FGA3','Opp Avg FTM','Opp Avg FTA','Opp Avg OR','Opp Avg DR',\n",
    "                'Opp Avg Ast','Opp Avg TO%','Opp Avg Stl%','Opp Avg Blk%','Opp Avg PF','Opp Avg TR','Opp Avg FGM2',\n",
    "                'Opp Avg FGA2','Opp Avg FG%','Opp Avg FG2%','Opp Avg FG3%','Opp Avg FGA3%','Opp Avg FT%',\n",
    "                'Opp Avg Pos','Opp Avg OEff','Net Team Avg FGM','Net Team Avg FGA','Net Team Avg FGM3',\n",
    "                'Net Team Avg FGA3','Net Team Avg FTM','Net Team Avg FTA','Net Team Avg OR','Net Team Avg DR',\n",
    "                'Net Team Avg Ast','Net Team Avg TO%','Net Team Avg Stl%','Net Team Avg Blk%','Net Team Avg PF',\n",
    "                'Net Team Avg TR','Net Team Avg FGM2','Net Team Avg FGA2','Net Team Avg FG%','Net Team Avg FG2%',\n",
    "                'Net Team Avg FG3%','Net Team Avg FGA3%','Net Team Avg FT%','Net Team Avg Pos','Net Team Avg OEff',\n",
    "                'Net Opp Avg FGM','Net Opp Avg FGA','Net Opp Avg FGM3','Net Opp Avg FGA3','Net Opp Avg FTM',\n",
    "                'Net Opp Avg FTA','Net Opp Avg OR','Net Opp Avg DR','Net Opp Avg Ast','Net Opp Avg TO%',\n",
    "                'Net Opp Avg Stl%','Net Opp Avg Blk%','Net Opp Avg PF','Net Opp Avg TR','Net Opp Avg FGM2',\n",
    "                'Net Opp Avg FGA2','Net Opp Avg FG%','Net Opp Avg FG2%','Net Opp Avg FG3%','Net Opp Avg FGA3%',\n",
    "                'Net Opp Avg FT%','Net Opp Avg Pos','Net Opp Avg OEff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74fef938",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = analysis.extract_training_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae13dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = analysis.extract_validation_data(feature_keys=feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3cfa5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "97f736a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1144fc",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1f382f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10000,max_features='sqrt',\n",
    "                                max_depth=5,random_state=100,n_jobs=2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30c497c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8118256365990505"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e64378c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6567164179104478"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2180432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = mm.bound_predictions(forest.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7141fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6125969406878569"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.score_model_predictions(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514607c",
   "metadata": {},
   "source": [
    "# Discussion and Conclusions\n",
    "\n",
    "Overall this competition ended up being much more challenging to solve with machine learning than I expected it to. As I approached development, I expected as I added more features and information to the models, performance would improve, which was certainly not the case. Based on the leaderboard and discussion in the forums, simple models seemed to perform very well this year. FiveThirtyEight also posted an [article](https://fivethirtyeight.com/features/the-stats-led-our-brackets-astray-this-march-madness-that-doesnt-happen-often/) on how some of the more advanced statistics weren't very predictive this year, which might explain why Phase 2 performance really wasn't any better than just knowing the final scores of games.\n",
    "\n",
    "In fact, just using the historical win percentages for seed-to-seed match-ups yielded my best score (0.60450) and would've placed 52nd overall out of 930 submissions.\n",
    "\n",
    "Another interesting finding was that the Logistic Regression model ofter performed better on the 'test' set during model training compared to the Random Forest models, however, the Random Forests performed better in the 2022 Tournament almost entirely across the board indicating a better ability to generalize.\n",
    "\n",
    "Approaching this competition next year, I think it will be more important to keep the 'score' of the model in perspective. Many of my models produced scores on the test set during training that would've been top 5 in the competition. Given the incredible variability of results in the tournmanent, it might be a better to focus on improving generalization than optimizing the third decimal place of an already very good training score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449de905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
